geom_vline(xintercept=0, color="black")
ggplot(cps, aes(x=earnings_c, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point", binwidth=10)+
geom_vline(xintercept=0, color="black")
cps$earnings_c<- round(cps$earnings_c, 0)
cps$bins <- cut(cps$earnings_c, breaks=20)
table(cps$bins)
ggplot(cps, aes(x=earnings_c, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point", bins=10)+
geom_vline(xintercept=0, color="black")
ggplot(cps, aes(x=bins, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point")+
geom_vline(xintercept=0, color="black")
cps$earnings_c<- round(cps$earnings_c, 0)
cps$bins <- cut(cps$earnings_c, breaks=10)
table(cps$bins)
ggplot(cps, aes(x=bins, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point")+
geom_vline(xintercept=0, color="black")
cps$earnings_c<- round(cps$earnings_c, 0)
cps$bins <- cut(cps$earnings_c, breaks=15)
table(cps$bins)
ggplot(cps, aes(x=bins, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point")+
geom_vline(xintercept=0, color="black")
cps$earnings_c<- round(cps$earnings_c, 0)
cps$bins <- cut(cps$earnings_c, breaks=20)
table(cps$bins)
ggplot(cps, aes(x=bins, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point")+
geom_vline(xintercept=0, color="black")
cps <- cps %>%
filter(cps$earnings_c <=-3 | cps$earnings_c >=3)
summary(lm(y ~D + earnings_c, data=cps))
table(cps$earnings_c)
cps <- cps %>%
filter(cps$earnings_c <=3 | cps$earnings_c >=-3)
table(cps$earnings_c)
cps <- cps %>%
filter(cps$earnings_c <=3 & cps$earnings_c >=-3)
summary(lm(y ~D + earnings_c, data=cps))
View(cps)
# Causal Inference Lab 8: Regression Discontinuity
# Spring 2022
# Benjamin S. Noble
# benjaminnoble.org
library(tidyverse)
library(haven)
# So, I had a great plan to create a plausibly realistic but fake RDD study.
# Turns out that didn't end up happening. I went a little off the deep end here
# but hey, you'll still learning something!
# As most RDD studies surely begin, someone looks at a program with a sharp
# cutoff and says "hey, what questions can I answer with this using an RDD?" One
# thing I thought of was that in the spring of 2021, President Biden and Congress
# passed the American Rescue Plan  which, among other things, provided $1,400
# stimulus payments to most Americans. Unlike some previous rounds of
# COVID-related stimulus funding, this round of funding had an eligibility
# requirement. Past a certain income threshold, Americans would no longer receive
# a stimulus payment.^[In reality, there was a phase-out between $75K and $80K
# for individuals and $150K to $160K for couples.] Income was determined by your
# 2020 tax return, so it was based on a previous income measure. Because the
# phase out and individuals vs families thing can get complicated, let's suppose
# instead that there was a sharp cutoff at $75K. You got the payment if you
# reported less than $75K on your 2020 tax return and otherwise you did not. Also,
# let's suppose that everyone filed individually.
# Armed with an identification strategy, let's come up with our question: does
# an increase in income cause one to be more likely to turn out to vote? There
# is definitely a correlation between income and voting in the US (and maybe a
# study about the causal effects?), but that relationship could simply be due to
# e.g., more knowledgeable people are both more likely to earn a higher income and
# learn about political issues and thus turn out to vote on those issues. It's
# not clear if the money itself has a causal effect. So, we will use an RDD to
# investigate whether increased income has a causal effect on voting.
# Sidebar: Actually, it makes more theoretical sense that having a higher income
# would enable one to e.g., access transportation to get to the polling place.
# So, it's not necessarily that the money itself is causing voting, but money
# facilitates access to mediators that enable more voting. Anyway...let's just
# move forward and investigate whether increasing your income in a given year (
# here, defined as receiving an unexpected $1,400) increases your probability of
# voting. We'll measure turnout as an individual's latent probability
# of turning out in the 2022 midterm elections that we somehow magically observe?
# To get started, let's read in the 2009 Current Population Survey data from
# Bruce Hansen (we used this in Lab 2). This is an economics dataset that has
# some basic information about many US households. Of interest to us is the
# earnings column, which will be our running (or forcing) variable. I have
# imported this data below and made some slight adjustments to the earnings
# variable to make it easier to work with. Specifically, I have i) divided by
# 1,000 just to make the units smaller and easier to work with, ii) added some
# random noise to make the data smoother and more continuous, iii) removed some
# outliers to facilitate plotting the data.
# Oh...also let's pretend this is data from 2020 and not 2009!
set.seed(0401)
library(haven)
cps <- read_dta('https://www.ssc.wisc.edu/~bhansen/econometrics/cps09mar.dta') %>%
# rename as pre-treatment earnings, divide by 1000 to make variable easier to
# use, and add noise to smooth out values which are reported as whole numbers
mutate(earnings_pre = earnings/1000 + rnorm(n(), 1, 2)) %>%
filter(earnings_pre < 150 & earnings_pre > 0) # trim outliers
# 1a) By convention, we often transform our running variable so that the cut-point
# is at 0 (rather than, e.g., 75). Although it won't necessarily change your
# findings, it will change the intercept. Let's follow convention. Create
# a new variable called `earnings_c` by subtracting 75 from the `earning_pre`
# variable. Then, assign treatment by creating a variable named `D` that takes
# on a value of 1 when a respondent's income is below the cut-point, and 0 when
# above. (Do use the specified names above, otherwise future code I've written
# for you below will not work).
library(dplyr)
cps <- cps %>%
mutate(earnings_c= earnings_pre - 75) %>%
mutate(D=ifelse(earnings_c <0, 1, 0))
# 1b) Create a plot with `earnings_c` on the x-axis and treatment (`D`) on the
# y-axis. Also, use a different color for treated and untreated units. What does
# this plot tell us?
library(gpplot2)
ggplot(cps, aes(x=earnings_c, y=D, color=D))+
geom_point()
#this tells us that we have a sharp RDD where probability of treatment goes from 0 to 1 based on the cutpoint
# I am going to create the treatment effect below using the following data-
# generating process. The baseline probability of turnout is 25%. Those in the
# treatment have an increase of 3 percentage points. Each additional $1,000 in
# earnings leads to a 0.2 percentage point increase in turnout. The error is
# normally distributed with an sd of 5. (Credit to Scott Cunningham for this
# code; https://mixtape.scunning.com/regression-discontinuity.html)
set.seed(0401)
cps <- cps %>%
mutate(y = 25 + 3 * D + .2 * earnings_pre  + rnorm(n(), 0, 5))
# 2) Estimate the effect of the treatment using the full data. That is, regress
# `y` on `D` and `earnings_c`. What do you conclude? Make sure you understand how
# to interpret what it is we are actually estimating here.
summary(lm(y ~D + earnings_c, data=cps))
#D and earnings have an effect on turnout
# 3a) Create a plot with `earnings_c` on the x-axis and `y` on the y-axis. Add
# the linear fitted lines (with the same slope on each side of the cut-point) to
# illustrate the effect of the treatment. (Hint: you can do this in ggplot by
# adding a column of the fitted values from your model to the `cps` data and
# calling `geom_line()`. Be sure to use different colors conditional on treatment
# so we can see the lines).
ols <- lm(y ~D + earnings_c, data=cps)
cps$fitted <- ols$fitted.values
library(ggplot2)
ggplot(cps, aes(x=earnings_c, y=y))+
geom_point()+
geom_line(aes(x=earnings_c, y=fitted, color=as.factor(D)))
#if they are treated they are more likely to turn out
# 3b) This plot is kind of messy. As such, people typically plot binned values of
# the running variable. To do this, first round income to the nearest (thousandth)
# dollar. Then take the average turnout probability in each of those strata. Plot
# the binned averages and your fitted lines from (3a). The discontinuity should be
# much clearer.
cps$earnings_c<- round(cps$earnings_c, 0)
cps$bins <- cut(cps$earnings_c, breaks=20)
table(cps$bins)
ggplot(cps, aes(x=bins, y=y))+
stat_summary(fun="mean", colour="red", size=2, geom= "point")+
geom_vline(xintercept=0, color="black")
# 4a) We used the full data to estimate this treatment effect. Now, subset your
# data to within $3,000 of the cut-point on each side. Re-estimate the linear
# model with constant slope. What do you conclude
cps <- cps %>%
filter(cps$earnings_c <=3 & cps$earnings_c >=-3)
summary(lm(y ~D + earnings_c, data=cps))
# we initialize the values inside the Simpson object
#' @export
setMethod("initialize", "Simpson",
function(.Object, x, y, result){
.Object@x = x
.Object@y = y
.Object@result = result
return(.Object)
}
)
#' \item \code{result} Value of numerical integration using Simpsons Rule
#' \item \code{x} The input
#' \item \code{y} The evaluated input
#' }
#'
#' @author Messi Lee: \email{hojunlee@@wustl.edu}
#' @seealso \code{\link{Simpson-class}}
#' @rdname Simpson-print
#' @aliases Simpson-class
#' @export
setClass(Class="Simpson",
representation = representation(
x = "numeric",
y = "numeric",
result = "numeric"
),
prototype = prototype(
x = c(),
y = c(),
result = c()
)
)
library(devtools)
library(roxygen2)
create("IntegrateIt")
library(devtools)
library(roxygen2)
create("IntegrateIt")
#load libraries
library(devtools)
library(roxygen2)
#set wd
setwd("~/Documents/GitHub/PS3/Untitled/PS5")
#load package
current.code <- as.package("integrateIt")
#load functions
load_all(current.code)
#make help file
document(current.code)
#test
#Trapezoid
integrateIt(1:10, function(x){x+1}, 0,5, rule = "Trapezoid")
# Simpson
integrateIt(seq(1, 10, 0.1), function(x){x+1}, 0,5, rule = "Simpson")
# This installs the package
devtools::install(current.code)
#create Simpson class
#' Simpson integration object
#' Simpson integration object
#'
#' objects in this class \code{Simpson} are created with the function \code{integrateIt}
#' Simpson integration object
#'
#' objects in this class \code{Simpson} are created with the function \code{integrateIt}
#'
#'
#' Simpson integration object
#'
#' objects in this class \code{Simpson} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Simpson' has the following slots:
#' \itemize{
#' Simpson integration object
#'
#' objects in this class \code{Simpson} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Simpson' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' Simpson integration object
#'
#' objects in this class \code{Simpson} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Simpson' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of values of same dimensionality as \code{x}
#' }
#' objects in this class \code{Simpson} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Simpson' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of values of same dimensionality as \code{x}
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#'
#' An object of the class `Simpson' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of values of same dimensionality as \code{x}
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#' @aliases Simpson
#' @rdname Simpson
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of values of same dimensionality as \code{x}
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#' @aliases Simpson
#' @rdname Simpson
#' @export
#create class - much of this comes from Jacob's code in class slides 18
#' \item \code{x} a vector of values
#' \item \code{y} a vector of values of same dimensionality as \code{x}
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#' @aliases Simpson
#' @rdname Simpson
#' @export
#create class - much of this comes from Jacob's code in class slides 18
#set class
setClass(Class = "Simpson",
x = "numeric",
integral = "numeric"
prototype = prototype(
y = c(),
),
)
#validity
check_simpson <- function(object){
#define values needed for integration
#bounds for x
a <- object@x[1]
b <- tail(object@x, 1)
#bounds for y
f_a <- object@y[1]
f_b <- tail(object@y, 1)
#n
n <- length(object@x)
#h
h <- (b - a) / n
#x
x_vec <- object@x[a < object@x & b > object@x]
#y
y_vec <- object@y[f_a < object@y & f_b > object@y]
#compute integral
result <- (h / 3) * (f_a + sum(4 * y_vec[c(T, F)]) + sum(2 * y_vec[c(F,T)]) + f_b)
#check integral result
if(result!=object@integral){return("integration incorrect")}
}
#set method, i.e., initialization
setMethod("initialize",
"Simpson",
function(.Object, ...){
value = callNextMethod()
validObject(value)
return(value)
}
)
setMethod(f = "print",
signature(x = "Simpson"),
definition = function(x){
print(x@integral)
})
#create Trapezoid class
#' Trapezoid integration object
#' Trapezoid integration object
#'
#' objects in this class \code{Trapezoid} are created with the function \code{integrateIt}
#' Trapezoid integration object
#'
#' objects in this class \code{Trapezoid} are created with the function \code{integrateIt}
#'
#'
#' Trapezoid integration object
#'
#' objects in this class \code{Trapezoid} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Trapezoid' has the following slots:
#' \itemize{
#' Trapezoid integration object
#'
#' objects in this class \code{Trapezoid} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Trapezoid' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' Trapezoid integration object
#'
#' objects in this class \code{Trapezoid} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Trapezoid' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of evaluated values
#' }
#' objects in this class \code{Trapezoid} are created with the function \code{integrateIt}
#'
#'
#' An object of the class `Trapezoid' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of evaluated values
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#'
#' An object of the class `Trapezoid' has the following slots:
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of evaluated values
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#' @aliases Trapezoid
#' @rdname Trapezoid
#' \itemize{
#' \item \code{integral} The integral
#' \item \code{x} a vector of values
#' \item \code{y} a vector of evaluated values
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#' @aliases Trapezoid
#' @rdname Trapezoid
#' @export
#create class - much of this comes from Jacob's code in class slides 18
#' \item \code{x} a vector of values
#' \item \code{y} a vector of evaluated values
#' }
#'
#' @author Annie Jarman: \email{a.a.jarman@wustl.edu}
#' @aliases Trapezoid
#' @rdname Trapezoid
#' @export
#create class - much of this comes from Jacob's code in class slides 18
#set class
setClass(Class = "Trapezoid",
x = "numeric",
integral = "numeric"
prototype = prototype(
y = c(),
),
)
#validity
check_trapezoid <- function(object){
#define values needed for integration
#bounds for x
a <- object@x[1]
b <- tail(object@x, 1)
#bounds for y
f_a <- object@y[1]
f_b <- tail(object@y, 1)
#n
n <- length(object@x)
#h
h <- (b - a) / n
#x
x_vec <- object@x[a < object@x & b > object@x]
#y
y_vec <- object@y[f_a < object@y & f_b > object@y]
#compute integral
result <- (h / 2) * (f_a + sum(2 * y_vals) + f_b)
#check integral result
if(result!=object@integral){return("integration incorrect")}
}
#set method, i.e., initialization
setMethod("initialize",
"Trapezoid",
function(.Object, ...){
value = callNextMethod()
validObject(value)
return(value)
}
)
setMethod(f = "print",
signature(x = "Trapezoid"),
definition = function(x){
print(x@integral)
})
#source document
library(devtools)
library(roxygen2)
#make generic
setGeneric(name = "integrateIt",
def = function(x, f_x, a, b, rule)
{standardGeneric("integrateIt")}
)
#set method
setMethod(f = "integrateIt",
definition = function(x, f_x, a, b, rule){
#extract values needed for integration
#x and y
x_vals <- x[x >= a & x <= b]
y_vals <- unlist(lapply(x_vals, f_x))
#n
n <- length(x_vals)
#h
h <- (b - a) / n
#use Simpson
if (rule == "Simpson") {
y_vals_mid <- y_vals[2:(n-1)]
result <- (h / 3) * (y_vals[1] + sum(4 * y_vals_mid[c(T, F)]) + sum(2 * y_vals_mid[c(F,T)]) + y_vals[n])
return(new("Simpson",
x = x_vals,
y = y_vals,
integral = result))
}
#use Trapezoid
if (rule == "Trapezoid") {
result <- (h / 2) * (y_vals[1] + sum(2 * y_vals[2:(n-1)]) + y_vals[n])
return(new("Trapezoid",
x = x_vals,
y = y_vals,
integral = result))
}
}
)
#load libraries
library(devtools)
library(roxygen2)
#set wd
setwd("~/Documents/GitHub/PS3/Untitled/PS5")
#load package
current.code <- as.package("integrateIt")
#load functions
load_all(current.code)
#make help file
document(current.code)
